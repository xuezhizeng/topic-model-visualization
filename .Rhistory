library(quanteda)
for(i in 1:100){
#sample 200
bootstrapped<-sample_n(df, 200, replace=TRUE)
bootstrapped$read_FRE<-readability(bootstrapped$texts, "Flesch")
#store results
year_FRE[i,]<-aggregate(bootstrapped$read_FRE, by=list(bootstrapped$year), FUN=mean)[,2]
party_FRE[i,]<-aggregate(bootstrapped$read_FRE, by=list(bootstrapped$party), FUN=mean)[,2]
}
colnames(year_FRE)<-names(table(df$year))
colnames(party_FRE)<-names(table(df$party))
std <- function(x) sd(x)/sqrt(length(x))
year_ses<-apply(year_FRE, 2, std)
year_means<-apply(year_FRE, 2, mean)
party_ses<-apply(party_FRE, 2, std)
party_means<-apply(party_FRE, 2, mean)
###Plot results--year
coefs<-year_means
ses<-year_ses
y.axis <- c(1:5)
min <- min(coefs - 2*ses)
max <- max(coefs + 2*ses)
var.names <- colnames(year_FRE)
adjust <- 0
par(mar=c(2,8,2,2))
plot(coefs, y.axis, type = "p", axes = F, xlab = "", ylab = "", pch = 19, cex = .8,
xlim=c(min,max),ylim = c(.5,6.5), main = "")
rect(min,.5,max,1.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,1.5,max,2.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,2.5,max,3.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,3.5,max,4.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,4.5,max,5.5, col = c("grey97"), border="grey90", lty = 2)
#rect(min,5.5,max,6.5, col = c("grey97"), border="grey90", lty = 2)
axis(1, at = seq(min,max,(max-min)/10),
labels = c(round(min+0*((max-min)/10),3),
round(min+1*((max-min)/10),3),
round(min+2*((max-min)/10),3),
round(min+3*((max-min)/10),3),
round(min+4*((max-min)/10),3),
round(min+5*((max-min)/10),3),
round(min+6*((max-min)/10),3),
round(min+7*((max-min)/10),3),
round(min+8*((max-min)/10),3),
round(min+9*((max-min)/10),3),
round(max,3)),tick = T,cex.axis = .75, mgp = c(2,.7,0))
axis(2, at = y.axis, label = var.names, las = 1, tick = FALSE, cex.axis =.8)
abline(h = y.axis, lty = 2, lwd = .5, col = "white")
segments(coefs-qnorm(.975)*ses, y.axis+2*adjust, coefs+qnorm(.975)*ses, y.axis+2*adjust, lwd =  1)
segments(coefs-qnorm(.95)*ses, y.axis+2*adjust-.035, coefs-qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
segments(coefs+qnorm(.95)*ses, y.axis+2*adjust-.035, coefs+qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
points(coefs, y.axis+2*adjust,pch=21,cex=.8, bg="white")
library(ggplot2)
plot(coefs, y.axis, type = "p", axes = F, xlab = "", ylab = "", pch = 19, cex = .8,
xlim=c(min,max),ylim = c(.5,6.5), main = "")
rect(min,.5,max,1.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,1.5,max,2.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,2.5,max,3.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,3.5,max,4.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,4.5,max,5.5, col = c("grey97"), border="grey90", lty = 2)
#rect(min,5.5,max,6.5, col = c("grey97"), border="grey90", lty = 2)
axis(1, at = seq(min,max,(max-min)/10),
labels = c(round(min+0*((max-min)/10),3),
round(min+1*((max-min)/10),3),
round(min+2*((max-min)/10),3),
round(min+3*((max-min)/10),3),
round(min+4*((max-min)/10),3),
round(min+5*((max-min)/10),3),
round(min+6*((max-min)/10),3),
round(min+7*((max-min)/10),3),
round(min+8*((max-min)/10),3),
round(min+9*((max-min)/10),3),
round(max,3)),tick = T,cex.axis = .75, mgp = c(2,.7,0))
axis(2, at = y.axis, label = var.names, las = 1, tick = FALSE, cex.axis =.8)
abline(h = y.axis, lty = 2, lwd = .5, col = "white")
segments(coefs-qnorm(.975)*ses, y.axis+2*adjust, coefs+qnorm(.975)*ses, y.axis+2*adjust, lwd =  1)
segments(coefs-qnorm(.95)*ses, y.axis+2*adjust-.035, coefs-qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
segments(coefs+qnorm(.95)*ses, y.axis+2*adjust-.035, coefs+qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
points(coefs, y.axis+2*adjust,pch=21,cex=.8, bg="white")
table(df$year)
aggregate(df$read_FRE, by=list(df$year), FUN=mean)
coefs<-party_means
ses<-party_ses
y.axis <- c(1:6)
min <- min(coefs - 2*ses)
max <- max(coefs + 2*ses)
var.names <- colnames(party_FRE)
adjust <- 0
par(mar=c(2,8,2,2))
plot(coefs, y.axis, type = "p", axes = F, xlab = "", ylab = "", pch = 19, cex = .8,
xlim=c(min,max),ylim = c(.5,6.5), main = "")
rect(min,.5,max,1.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,1.5,max,2.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,2.5,max,3.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,3.5,max,4.5, col = c("grey95"), border="grey90", lty = 2)
rect(min,4.5,max,5.5, col = c("grey97"), border="grey90", lty = 2)
rect(min,5.5,max,6.5, col = c("grey97"), border="grey90", lty = 2)
axis(1, at = seq(min,max,(max-min)/10),
labels = c(round(min+0*((max-min)/10),3),
round(min+1*((max-min)/10),3),
round(min+2*((max-min)/10),3),
round(min+3*((max-min)/10),3),
round(min+4*((max-min)/10),3),
round(min+5*((max-min)/10),3),
round(min+6*((max-min)/10),3),
round(min+7*((max-min)/10),3),
round(min+8*((max-min)/10),3),
round(min+9*((max-min)/10),3),
round(max,3)),tick = T,cex.axis = .75, mgp = c(2,.7,0))
axis(2, at = y.axis, label = var.names, las = 1, tick = FALSE, cex.axis =.8)
abline(h = y.axis, lty = 2, lwd = .5, col = "white")
segments(coefs-qnorm(.975)*ses, y.axis+2*adjust, coefs+qnorm(.975)*ses, y.axis+2*adjust, lwd =  1)
segments(coefs-qnorm(.95)*ses, y.axis+2*adjust-.035, coefs-qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
segments(coefs+qnorm(.95)*ses, y.axis+2*adjust-.035, coefs+qnorm(.95)*ses, y.axis+2*adjust+.035, lwd = .9)
points(coefs, y.axis+2*adjust,pch=21,cex=.8, bg="white")
##real world data
table(df$party)
aggregate(df$read_FRE, by=list(df$party), FUN=mean)
df$
browseVignettes(package = "dplyr")
0.1*9
###Make sure you have the appropriate packages installed
install.packages("quanteda")
install.packages("topicmodels")
install.packages("ggplot2")
library(quanteda)
library(topicmodels)
library(ggplot2)
###First, you need to go to my github and download the data
###Save the two folders to your desktop
setwd("/Users/lesliehuang/Desktop/Text_as_Data-master 2")
###Get the list of files
g1 <- list.files("govdates/", full.names=TRUE)
g2 <- list.files("oppdates/",  full.names=TRUE)
files<-c(g1, g2)
###read in the tweets
tweets <- lapply(files, readLines)
##Combine all the tweets per day to form the documents
tweets<-lapply(tweets, function(x) paste(x, collapse=" "))
txt <- unlist(tweets)
##Tokenize and clean the text
txt<-tokenize(txt, removePunct = TRUE, removeTwitter = FALSE )
##Convert to Document Feature Matrix (AKA Document Term Matrix)
mat <-dfm(txt, stem=TRUE, language = "spanish", ignoredFeatures = stopwords(kind="spanish"), toLower=T)
##Set number of topics
k <-50
SEED<-2010
##Run the topic model
TM<-list(Gibbs = LDA(mat, k = k, method = "Gibbs",  control = list(seed = SEED, burnin = 3,thin = 30, iter = 30)))
##Store the results of the distribution of topics over documents
doc_topics<-TM[["Gibbs"]]@gamma
##Store the results of words over topics
words_topics<-TM[["Gibbs"]]@beta
###Look at a visualization of the topics
###transpose the data so that the days are columns
doc_topics<-t(doc_topics)
#arrange topics
max<-apply(doc_topics, 1, which.max)
##write a function that finds the second max
which.max2<-function(x){
which(x == sort(x,partial=(k-1))[k-1])
}
max222<- apply(doc_topics, 1, which.max2)
max222<-sapply(max222, max)
##combine data
index<-seq(1:162)
top2<-data.frame(max, max222, index)
dates<-seq(as.Date("2013/12/18"), by="days", length=162)
gov2<-data.frame(dates, max[1:162], max222[1:162])
opp2<-data.frame(dates, max[163:324], max222[163:324])
doc_topics<-t(doc_topics)
max<-apply(doc_topics, 1, which.max)
max222<- apply(doc_topics, 1, which.max2)
max222<-sapply(max222, max)
index<-seq(1:162)
top2<-data.frame(max, max222, index)
dates<-seq(as.Date("2013/12/18"), by="days", length=162)
gov2<-data.frame(dates, max[1:162], max222[1:162])
opp2<-data.frame(dates, max[163:324], max222[163:324])
####plot
z<-ggplot(gov2, aes(x=index, y=max.1.162., pch="First"))
z + geom_point(aes(x=index, y=max222.1.162., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Government")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
geom_vline(xintercept=57) +
geom_vline(xintercept=143)  +
geom_vline(xintercept=114, linetype=2) +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
summary(immigNewsCorpus)
install.packages("austin", repos="http://r-forge.r-project.org", type="source", dependencies=TRUE)
libraries <- c("foreign", "utils", "stargazer", "dplyr", "devtools", "quanteda", "quantedaData", "topicmodels", "lda", "stm", "LDAvis", "austin")
lapply(libraries, require, character.only=TRUE)
set.seed(1234)
#####################################################
# Setup
data(immigNewsCorpus, package = "quantedaData")
topPapers <- sort(table(immigNewsCorpus[["paperName"]]), decreasing = TRUE)
reducedCorpus <- subset(immigNewsCorpus, paperName %in% names(topPapers)[1:4])
table(reducedCorpus[["paperName"]])
summary(immigNewsCorpus)
load("~/Dropbox/HW 3/custom_stopwords.RData")
custom_stopwords[573:588]
newsdfm <- dfm(reducedCorpus, ignoredFeatures = custom_stopwords, stem = TRUE)
summary(newsdfm)
newsdfm@Dimnames$features[1]
newsdfm@Dimnames$features[[1]]
newsdfm@Dimnames$features[2
]
newsdfm@Dimnames$features$1
reducedCorpus$metadata[1]
reducedCorpus$metadata
reducedCorpus[["guardian"]]
reducedCorpus[["paperName"]]
doc_topics <- TM@gamma
TM <- LDA(trim_news, 30, method = "Gibbs", control = list(burnin = 3, thin = 30, iter = 30))
newsdfm <- dfm(reducedCorpus, ignoredFeatures = custom_stopwords, stem = TRUE)
# (c) Trim
trim_news <- quanteda::trim(newsdfm, minCount = 30, minDoc = 20)
# (d) Fit LDA
TM <- LDA(trim_news, 30, method = "Gibbs", control = list(burnin = 3, thin = 30, iter = 30))
doc_topics <- TM@gamma
View(doc_topics)
View(doc_topics)
doc_topics <- doc_topics[1:804]
max<-apply(doc_topics, 1, which.max)
doc_topics<-t(doc_topics)
max<-apply(doc_topics, 1, which.max)
which.max2<-function(x){
which(x == sort(x,partial=(k-1))[k-1])
}
max222 <- apply(doc_topics, 1, which.max2)
max222 <- sapply(max222, max)
dates
dates <-seq(1:393)
index <- seq(1:393)
top2 < -data.frame(max, max222, index)
max222 <- apply(doc_topics, 1, which.max2)
max222
doc_topics<-t(doc_topics)
max222 <- apply(doc_topics, 1, which.max2)
doc_topics<-t(doc_topics)
max<-apply(doc_topics, 1, which.max)
max222 <- apply(doc_topics, 1, which.max2)
View(doc_topics)
View(doc_topics)
doc_topics <- TM@gamma
doc_topics <- doc_topics[1:804]
doc_topics <- TM@gamma
View(doc_topics)
View(doc_topics)
doc_topics[1:2]
doc_topics <- doc_topics[1:804,]
doc_topics<-t(doc_topics)
max<-apply(doc_topics, 1, which.max)
doc_topics<-t(doc_topics)
max<-apply(doc_topics, 1, which.max)
max222 <- apply(doc_topics, 1, which.max2)
max222 <- sapply(max222, max)
##write a function that finds the second max
which.max2<-function(x){
which(x == sort(x,partial=(k-1))[k-1])
}
max222 <- apply(doc_topics, 1, which.max2)
doc_topics<-t(doc_topics)
max222 <- apply(doc_topics, 1, which.max2)
max222 <- sapply(max222, max)
doc_topics<-t(doc_topics)
max222 <- apply(doc_topics, 1, which.max2)
index <- seq(1:393)
top2 < -data.frame(max, max222, index)
rm(list=ls())
###Running LDA
###Make sure you have the appropriate packages installed
install.packages("quanteda")
install.packages("topicmodels")
install.packages("ggplot2")
library(quanteda)
library(topicmodels)
library(ggplot2)
###First, you need to go to my github and download the data
###Save the two folders to your desktop
setwd("/Users/lesliehuang/Desktop/Text_as_Data-master 2")
###Get the list of files
g1 <- list.files("govdates/", full.names=TRUE)
g2 <- list.files("oppdates/",  full.names=TRUE)
files<-c(g1, g2)
###read in the tweets
tweets <- lapply(files, readLines)
##Combine all the tweets per day to form the documents
tweets<-lapply(tweets, function(x) paste(x, collapse=" "))
txt <- unlist(tweets)
##Tokenize and clean the text
txt<-tokenize(txt, removePunct = TRUE, removeTwitter = FALSE )
##Convert to Document Feature Matrix (AKA Document Term Matrix)
mat <-dfm(txt, stem=TRUE, language = "spanish", ignoredFeatures = stopwords(kind="spanish"), toLower=T)
install.packages("quanteda")
install.packages("ggplot2")
install.packages("topicmodels")
install.packages("ggplot2")
install.packages("topicmodels")
install.packages("topicmodels")
##Set number of topics
k <-50
SEED<-2010
##Run the topic model
TM<-list(Gibbs = LDA(mat, k = k, method = "Gibbs",  control = list(seed = SEED, burnin = 3,thin = 30, iter = 30)))
##Store the results of the distribution of topics over documents
doc_topics<-TM[["Gibbs"]]@gamma
doc_topics<-t(doc_topics)
max<-apply(doc_topics, 1, which.max)
which.max2<-function(x){
which(x == sort(x,partial=(k-1))[k-1])
}
max222<- apply(doc_topics, 1, which.max2)
max222<-sapply(max222, max)
doc_topics<-t(doc_topics)
max<-apply(doc_topics, 1, which.max)
max222<- apply(doc_topics, 1, which.max2)
max222<-sapply(max222, max)
index<-seq(1:162)
top2<-data.frame(max, max222, index)
dates<-1:162
gov2<-data.frame(dates, max[1:162], max222[1:162])
opp2<-data.frame(dates, max[163:324], max222[163:324])
z<-ggplot(gov2, aes(x=index, y=max.1.162., pch="First"))
z + geom_point(aes(x=index, y=max222.1.162., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Government")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
geom_vline(xintercept=57) +
geom_vline(xintercept=143)  +
geom_vline(xintercept=114, linetype=2) +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
# Set up the workspace and libraries
rm(list=ls())
setwd("/Users/lesliehuang/Dropbox/HW 3")
install.packages("austin", repos="http://r-forge.r-project.org", type="source", dependencies=TRUE)
libraries <- c("foreign", "utils", "stargazer", "dplyr", "devtools", "quanteda", "quantedaData", "topicmodels", "lda", "stm", "LDAvis", "austin", "ggplot2")
lapply(libraries, require, character.only=TRUE)
set.seed(1234)
install.packages("austin", repos = "http://r-forge.r-project.org",
rm(list=ls())
setwd("/Users/lesliehuang/Dropbox/HW 3")
rm(list=ls())
setwd("/Users/lesliehuang/Dropbox/HW 3")
set.seed(1234)
data(immigNewsCorpus, package = "quantedaData")
# Question 1
# (a) Select four most common newspapers
topPapers <- sort(table(immigNewsCorpus[["paperName"]]), decreasing = TRUE)
reducedCorpus <- subset(immigNewsCorpus, paperName %in% names(topPapers)[1:4])
table(reducedCorpus[["paperName"]])
load("~/Dropbox/HW 3/custom_stopwords.RData")
custom_stopwords[573:588]
newsdfm <- dfm(reducedCorpus, ignoredFeatures = custom_stopwords, stem = TRUE)
# (c) Trim
trim_news <- quanteda::trim(newsdfm, minCount = 30, minDoc = 20)
# (d) Fit LDA
TM <- LDA(trim_news, 30, method = "Gibbs", control = list(burnin = 3, thin = 30, iter = 30))
doc_topics <- TM@gamma
doc_topics <- doc_topics[1:804,]
max<-apply(doc_topics, 1, which.max)
which.max2<-function(x){
which(x == sort(x,partial=(k-1))[k-1])
}
max222 <- apply(doc_topics, 1, which.max2)
k <- 30
max222 <- apply(doc_topics, 1, which.max2)
max222 <- sapply(max222, max)
index <- seq(1:393)
top2 < -data.frame(max, max222, index)
top2 < -data.frame(max, max222, index)
index <- seq(1:393)
top2 <- data.frame(max, max222, index)
index <- seq(1:804)
top2 <- data.frame(max, max222, index)
gov2<-data.frame(max[1:393], max222[1:393])
opp2<-data.frame(max[394:804], max222[394:804])
guardian <- data.frame(max[1:393], max222[1:393])
mail <- data.frame(max[394:804], max222[394:804])
z<-ggplot(guardian, aes(x=index, y=max.1.162., pch="First"))
z + geom_point(aes(x=index, y=max222.1.162., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Guardian")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
geom_vline(xintercept=57) +
geom_vline(xintercept=143)  +
geom_vline(xintercept=114, linetype=2) +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
z<-ggplot(guardian, aes(x=index, y=max.1.393., pch="First"))
z + geom_point(aes(x=index, y=max222.1.393., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Guardian")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
geom_vline(xintercept=57) +
geom_vline(xintercept=143)  +
geom_vline(xintercept=114, linetype=2) +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
max.1.393
max.1.393.
max[1]
max[1:393]
max[394]
indexg <- seq(1:393)
indexdm <- seq(394:804)
z<-ggplot(guardian, aes(x=indexg, y=max.1.393., pch="First"))
z + geom_point(aes(x=indexg, y=max222.1.393., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Guardian")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
geom_vline(xintercept=57) +
geom_vline(xintercept=143)  +
geom_vline(xintercept=114, linetype=2) +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
z<-ggplot(guardian, aes(x=indexg, y=max.1.393., pch="First"))
z + geom_point(aes(x=indexg, y=max222.1.393., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Guardian")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
z<-ggplot(mail, aes(x=indexdm, y=max.394.804., pch="First"))
z + geom_point(aes(x=indexg, y=max222.394.804., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Guardian")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
z<-ggplot(mail, aes(x=indexdm, y=max.394.804., pch="First"))
z + geom_point(aes(x=indexdm, y=max222.394.804., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Guardian")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
z<-ggplot(mail, aes(x=indexdm, y=max.394.804., pch="First"))
z + geom_point(aes(x=indexdm, y=max222.394.804., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Daily Mail")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
z<-ggplot(guardian, aes(x=indexg, y=max.1.393., pch="First"))
z + geom_point(aes(x=indexg, y=max222.1.393., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Guardian")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
ggsave("guardian.pdf")
# plot top 2 topics per document for daily mail articles
z<-ggplot(mail, aes(x=indexdm, y=max.394.804., pch="First"))
z + geom_point(aes(x=indexdm, y=max222.394.804., pch="Second") ) +theme_bw() + ylab("Topic Number")  + ggtitle("Daily Mail")  +
xlab(NULL) + theme(axis.ticks = element_blank(), axis.text.x = element_blank()) + geom_point() +
scale_shape_manual(values=c(18, 1), name = "Topic Rank")
ggsave("mail.png")
ggsave("mail.pdf")
get_topics(TM)
postTopics <- data.frame(posterior(TM)$topics)
View(postTopics)
View(postTopics)
x <- sapply(rownames(postTopics),strsplit,'_')
x
paperNames <- sapply(x, head, n=1)
postTopics["paper"]<- paperNames
View(postTopics)
View(postTopics)
postTopics <- postTopics[-paperNames]
postTopics["paper"][1]
postTopics["paper"][[1]
]
postTopics["paper"][[1]]
postTopics[1,31
]
paperNames
postTopics["paper"] <- NA
reducedCorpus[["paperName"]]
postTopics["paper"] <- NA
postTopics[1:393, 31] <- "guardian"
postTopics[394:804, 31] <- "dailymail"
postTopics[805:1315, 31] <- "telegraph"
postTopics[1316:1667, 31] <- "times"
postTopics
library(plyr)
byPaperTopics <- ddply(postTopics, "paper", numcolwise(mean))
barplot(byPaperTopics$X1, names.arg=byPaperTopics$paper, beside=TRUE)
View(byPaperTopics)
View(byPaperTopics)
colnames(byPaperTopics) <- 1:30
colnames(byPaperTopics[1])
colnames(byPaperTopics) <- paste("topic", 1:30)
byPaperTopics <- t(byPaperTopics)
byPaperTopics <- t(byPaperTopics)
rownames(byPaperTopics) <- byPaperTopics[1,]
byPaperTopics[1,]
byPaperTopics[[1]]
rownames(byPaperTopics) <- byPaperTopics[[1:4]]
byPaperTopics[[2]]
rownames(byPaperTopics) <- c("guardian", "dailymail", "telegraph", "times")
byPaperTopics <- byPaperTopics[-1]
byPaperTopics <- ddply(postTopics, "paper", numcolwise(mean))
rownames(byPaperTopics) <- c("guardian", "dailymail", "telegraph", "times")
byPaperTopics <- byPaperTopics[-"paper"]
byPaperTopics <- byPaperTopics[2:31]
colnames(byPaperTopics) <- paste("topic", 1:30)
byPaperTopics <- t(byPaperTopics)
hist(byPaperTopics)
byPaperTopics[1,]
byPaperTopics[,1]
hist(byPaperTopics[,1])
stargazer(byPaperTopics, title="Average Contribution of Each Topic to Newspaper", summary = FALSE)
LDApost <- posterior(TM)
LDApost <- posterior(TM)
TM$terms
LDApost <- posterior(TM)
jsonLDA <- createJSON(phi = LDApost$terms,
theta = LDApost$topics,
doc.length = ntoken(newsdfm),
vocab = features(newsdfm),
term.frequency = colSums(newsdfm))
serVis(jsonLDA, out.dir = "visCollLDA", open.browser = TRUE)
jsonLDA <- createJSON(phi = LDApost$terms,
theta = LDApost$topics,
doc.length = ntoken(trim_news),
vocab = features(trim_news),
term.frequency = colSums(trim_news))
serVis(jsonLDA, out.dir = "visCollLDA", open.browser = TRUE)
install.packages("serVic")
install.packages("serVis")
install.packages("servr")
library(servr)
jsonLDA <- createJSON(phi = LDApost$terms,
theta = LDApost$topics,
doc.length = ntoken(trim_news),
vocab = features(trim_news),
term.frequency = colSums(trim_news))
serVis(jsonLDA, out.dir = "visCollLDA", open.browser = TRUE)
